{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track ARs at consecutive time steps to form tracks\n",
    "\n",
    "This notebook tracks detected ARs at individual time steps to form tracks.\n",
    "\n",
    "Specifically, assume we have detected $n$ ARs at time $t$, and $m$ ARs at time $t+1$. There are theoretically $n \\times m$ possible associations to link these two groups of ARs. Of cause not all of them are meaningful. The rules that are applied in the association process are:\n",
    "\n",
    "1. **nearest neighbor** principle: for any AR at time $t$, the nearest AR at time $t+1$ \"wins\" and is associated with it, subject to that:\n",
    "2. the **inter-AR distance (H)** is $\\le 1200 \\, km$.\n",
    "3. no merging or splitting is allowed, any AR at time $t$ can only be linked to one AR at time $t+1$, similarly, any AR at time $t+1$ can only be linked to one AR at time $t$.\n",
    "4. after all associations at any give time point have been created, any left-over AR at time $t+1$ forms a track on their own, and waits to be associated in the next iteration between $t+1$ and $t+2$.\n",
    "5. all tracks they do not get updated during the $t$ - $t+1$ process terminates. This assumes that no gap in the track is allowed. \n",
    "\n",
    "The remaining important question is how to define that **inter-AR distance (H)**. Here we adopt a modified *Hausdorff distance* definition:\n",
    "\n",
    "\\begin{equation}\n",
    "\tH(A,B) \\equiv min \\{ h_f(A,B), h_b(A,B) \\}\n",
    "\\end{equation}\n",
    "\n",
    "where $H(A, B)$ is the *modified Hausdorff distance* from track $A$ to track $B$,\n",
    "$h_f(A,B)$ is the *forward Hausdorff distance* from $A$ to $B$, and $h_b(A,B)$ the *backward Hausdorff distance* from $A$ to $B$. They are defined, respectively, as:\n",
    "\n",
    "\\begin{equation}\n",
    "\th_f(A, B) \\equiv \\operatorname*{max}_{a \\in A} \\{ \\operatorname*{min}_{b \\in B} \\{\n",
    "\t\td_g(a,b) \\} \\}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "namely, the largest great circle distance of all distances from a point in $A$ to the\n",
    "closest point in $B$. And the backward Hausdorff distance is:\n",
    "\n",
    "\\begin{equation}\n",
    "\th_b(A, B) \\equiv \\operatorname*{max}_{b \\in B} \\{ \\operatorname*{min}_{a \\in A} \\{\n",
    "\t\td_g(a,b) \\} \\}\n",
    "\\end{equation}\n",
    "\n",
    "Note that in general $h_f \\neq h_b$. Unlike the standard definition of\n",
    "Hausdorff distance that takes the maximum of $h_f$ and $h_b$, we take the\n",
    "minimum of the two. \n",
    "\n",
    "The rationale behind this modification is that merging/splitting of ARs mostly\n",
    "happen in an end-to-end manner, during which a sudden increase/decrease in the\n",
    "length of the AR induce misalignment among the anchor points. Specifically,\n",
    "merging (splitting) tends to induce large backward (forward) Hausdorff\n",
    "distance.  Therefore $min \\{ h_f(A,B), h_b(A,B) \\}$ offers a more faithful\n",
    "description of the spatial closeness of ARs. For merging/splitting events in a\n",
    "side-to-side manner, this definition works just as well.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In production you would use the `river_tracker2.py` for this step.\n",
    "\n",
    "\n",
    "## Input data\n",
    "\n",
    "* `ar_records_1984-03-01_00-00-00-1984-03-09_18-00-00.csv`: a csv table saving various attributes for each detected AR appearance at all time steps.\n",
    "\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Make sure you have successfully run the previous notebook.\n",
    "2. Execute the following code blocks in sequence.\n",
    "\n",
    "\n",
    "## Results\n",
    "\n",
    "* `ar_tracks_1984.csv`: a csv table listing various attributes for each AR track.\n",
    "* `plots/ar_track_198431.png` (optional): plot of the geographical locations of the track with id `198405` during its evolutions.\n",
    "* `plots/linkages_scheme_simple_1984-03-10_12-00-00.png` (optional): schematic illustration of the association process using the modified Hausdorff distance as the inter-AR distance measure between the time step of `1984-03-10_12-00-00` and the one before it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters\n",
    "\n",
    "As before, first we give the locations to the input and output data.\n",
    "\n",
    "`SCHEMATIC` is boolean flag controls whether a schematic illustration of the track association process is created.\n",
    "\n",
    "`LAT1`, `LAT2`, `LON1` and `LON2` control the domain to plot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "\n",
    "RECORD_FILE=os.path.join('1984', 'ar_records_1984-03-01_00-00-00-1984-03-09_18-00-00.csv')\n",
    "OUTPUTDIR=os.path.join('.', '1984')\n",
    "\n",
    "SCHEMATIC=True   # plot schematic or not\n",
    "\n",
    "LAT1=0; LAT2=90; LON1=80; LON2=440         # domain to plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TRACK_PARAMS` is the dict containing important parameters during the tracking process.\n",
    "\n",
    "* `time_gap_allow`: int, hours, the temporal gap allowed to link 2 records. For instance, if input data has 6-hourly resolution, and `time_gap_allow` is set to 6, then only consecutive records are allowed to be linked. If `time_gap_allow` is 12, then a single gap in time can be allowed.\n",
    "* `num_anchors`: int, number of (roughly) equally spaced points along the AR axis to use as anchor points. Anchors are used to compute the Hausdorff distances between ARs.\n",
    "* `track_scheme`: 'simple' or 'full'. If 'simple', each track is a topological simple path, i.e. no merging or splitting is allowed. If 'full', merging and splitting are allowed. For most applications 'simple' makes good sense. 'full' scheme is useful for case studies, e.g. you are interested how 2 particular ARs are merging/splitting.\n",
    "* `max_dist_allow`: float, $km$, maximum Hausdorff distance to link 2 ARs. About $\\sim 1000 \\, km$ is a good choice for 6-hourly data, and this does not seem to be a sensitive parameter. If using daily data, you should probably choose a larger number.\n",
    "* `min_duration`: int, minimum required number of hours of a track.\n",
    "* `min_nonrelax`: int, minimum required number of non-relaxed records in a track. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_PARAMS={}\n",
    "# Int, hours, gap allowed to link 2 records. Should be the time resolution of\n",
    "# the data.\n",
    "TRACK_PARAMS['time_gap_allow']=6\n",
    "# int, number of anchor points along the axis\n",
    "TRACK_PARAMS['num_anchors']=7\n",
    "# tracking scheme. 'simple': all tracks are simple paths.\n",
    "# 'full': use the network scheme, tracks are connected by their joint points.\n",
    "TRACK_PARAMS['track_scheme']='simple'  # 'simple' | 'full'\n",
    "# int, max Hausdorff distance in km to define a neighborhood relationship\n",
    "TRACK_PARAMS['max_dist_allow']=1200  # km\n",
    "# int, min duration in hrs to keep a track.\n",
    "TRACK_PARAMS['min_duration']=24\n",
    "# int, min number of non-relaxed records in a track to keep a track.\n",
    "TRACK_PARAMS['min_nonrelax']=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------Import modules-------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import funcs,plot\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.patches as patches\n",
    "from river_tracker2 import convarray, trackARs2, filterTracks, plotAR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then read in the data from the previous step -- the `csv` table containing AR records at individual time points.\n",
    "\n",
    "`dtypes` and `converters` are used to convert the data into suitable formats.\n",
    "\n",
    "After reading, we print out the first few records, just to remind of ourselves what type of data we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------Read in records---------------------\n",
    "print('\\n### <river_tracker2>: Read in file:\\n',RECORD_FILE)\n",
    "\n",
    "keys=['id', 'time', 'contour_y', 'contour_x', 'centroid_y', 'centroid_x',\n",
    "        'axis_y', 'axis_x', 'axis_rdp_y', 'axis_rdp_x',\n",
    "        'area', 'length', 'width', 'iso_quotient', 'LW_ratio',\n",
    "        'strength', 'strength_ano', 'strength_std',\n",
    "        'mean_angle', 'is_relaxed']\n",
    "\n",
    "convkeys=['contour_y', 'contour_x',\n",
    "        'axis_y', 'axis_x', 'axis_rdp_y', 'axis_rdp_x']\n",
    "\n",
    "converters=dict([(keyii, convarray) for keyii in convkeys])\n",
    "\n",
    "dtypes={'id': 'int', 'time': 'str',\n",
    "        'area': np.float64, 'length': np.float64, 'width': np.float64,\n",
    "        'iso_quotient': np.float64, 'LW_ratio': np.float64,\n",
    "        'strength': np.float64, 'strength_ano': np.float64,\n",
    "        'strength_std': np.float64,\n",
    "        'mean_angle': np.float64, 'is_relaxed': 'bool'}\n",
    "\n",
    "ardf=pd.read_csv(RECORD_FILE,dtype=dtypes,converters=converters)\n",
    "ardf.head(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make sure the output directories exist, before we start writing results into them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(OUTPUTDIR):\n",
    "    os.makedirs(OUTPUTDIR)\n",
    "\n",
    "if SCHEMATIC:\n",
    "    plot_dir=os.path.join(OUTPUTDIR, 'plots')\n",
    "    if not os.path.exists(plot_dir):\n",
    "        os.makedirs(plot_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The association process is handled with this single function. \n",
    "\n",
    "`ardf` is the `pandas.DataFrame` object we just read in.\n",
    "`track_list` is a list of `AR` objects, the class definition can be found in `river_tracker2.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_list=trackARs2(ardf,TRACK_PARAMS,plot_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a peak into what `track_list` contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(track_list))\n",
    "print(track_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_list[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_list[0].duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_list[2].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_list[2].duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `AR` object in `track_list` stores a sequence of AR records that form a single track. The 1st one, `track_list[0]` is a short track with only 2 records, lasting only for 6 hours. This one will be filtered out given a minimum duration requirement of 24 hours.\n",
    "\n",
    "The 3rd one, `track_list[2]`, lasted for 24 hours.\n",
    "\n",
    "To filter out short tracks, and those that consist only of *relaxed* AR records: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------Filter tracks------------------\n",
    "track_list=filterTracks(track_list,TRACK_PARAMS)\n",
    "print(len(track_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that originally 31 tracks were found, now the number has dropped to 11.\n",
    "\n",
    "Lets plot out the sequence of an AR. Only the AR axis is plotted, and a black-to-yellow color scheme is used to indicate the evolution of the AR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latax=np.arange(LAT1, LAT2)\n",
    "lonax=np.arange(LON1, LON2)\n",
    "\n",
    "plot_ar=track_list[6]\n",
    "\n",
    "figure=plt.figure(figsize=(12,6),dpi=100)\n",
    "ax=figure.add_subplot(111)\n",
    "plotAR(plot_ar,latax,lonax,True,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last step, save the results to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------Save output-------------------\n",
    "for ii in range(len(track_list)):\n",
    "    tii=track_list[ii]\n",
    "    trackidii='%d%d' %(tii.data.loc[0,'time'].year, ii+1)\n",
    "    tii.data.loc[:,'trackid']=trackidii\n",
    "    tii.trackid=trackidii\n",
    "\n",
    "    if ii==0:\n",
    "        trackdf=tii.data\n",
    "    else:\n",
    "        trackdf=pd.concat([trackdf,tii.data],ignore_index=True)\n",
    "\n",
    "    figure=plt.figure(figsize=(12,6),dpi=100)\n",
    "    ax=figure.add_subplot(111)\n",
    "    plotAR(tii,latax,lonax,True,ax=ax)\n",
    "\n",
    "    #----------------- Save plot------------\n",
    "    plot_save_name='ar_track_%s' %trackidii\n",
    "    plot_save_name=os.path.join(plot_dir,plot_save_name)\n",
    "    print('\\n# <river_tracker2>: Save figure to', plot_save_name)\n",
    "    figure.savefig(plot_save_name+'.png',dpi=100,bbox_inches='tight')\n",
    "\n",
    "    plt.close(figure)\n",
    "\n",
    "\n",
    "#--------Save------------------------------------\n",
    "abpath_out=os.path.join(OUTPUTDIR,'ar_tracks_1984.csv')\n",
    "print('\\n### <river_tracker2>: Saving output to:\\n',abpath_out)\n",
    "trackdf.to_csv(abpath_out,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
